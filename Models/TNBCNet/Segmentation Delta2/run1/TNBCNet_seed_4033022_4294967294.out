This job can be monitored from: https://job.c3se.chalmers.se/alvis/4033022
üî• Device: cuda | Seed: 2025
üöÄ Generating cross-validation loaders...
üì¶ Initializing model with 4 input channels...
üî¨ Visualizing a sample from the training set:
‚úÖ Initialized TNBCDataset with 1184 patients | mode=delta2 | segmentation=True
‚úÖ Initialized TNBCDataset with 296 patients | mode=delta2 | segmentation=True
Label: 0.0
Label: 1.0
‚úÖ Initialized TNBCDataset with 1184 patients | mode=delta2 | segmentation=True
‚úÖ Initialized TNBCDataset with 296 patients | mode=delta2 | segmentation=True
Using TNBCNet model
üîÑ Fold 1
‚úÖ Applied custom weight initialization
Class distribution: 396 positives, 788 negatives
Using pos_weight: 1.99
üîç Finding optimal learning rate...
üöÄ Training...
AUC: 0.4782, Inverse AUC: 0.5218 ‚Üê USING THIS
Epoch 1, Train Loss: 0.9232, Val Loss: 0.9344, AUC: 0.5218
AUC: 0.4949, Inverse AUC: 0.5051 ‚Üê USING THIS
Epoch 2, Train Loss: 0.9227, Val Loss: 0.9342, AUC: 0.5051
AUC: 0.5018 ‚Üê USING THIS, Inverse AUC: 0.4982
Epoch 3, Train Loss: 0.9226, Val Loss: 0.9338, AUC: 0.5018
AUC: 0.5171 ‚Üê USING THIS, Inverse AUC: 0.4829
Epoch 4, Train Loss: 0.9222, Val Loss: 0.9334, AUC: 0.5171
AUC: 0.5305 ‚Üê USING THIS, Inverse AUC: 0.4695
Epoch 5, Train Loss: 0.9248, Val Loss: 0.9336, AUC: 0.5305
AUC: 0.5421 ‚Üê USING THIS, Inverse AUC: 0.4579
Epoch 6, Train Loss: 0.9242, Val Loss: 0.9334, AUC: 0.5421
AUC: 0.5531 ‚Üê USING THIS, Inverse AUC: 0.4469
Epoch 7, Train Loss: 0.9230, Val Loss: 0.9329, AUC: 0.5531
AUC: 0.5616 ‚Üê USING THIS, Inverse AUC: 0.4384
Epoch 8, Train Loss: 0.9208, Val Loss: 0.9327, AUC: 0.5616
AUC: 0.5732 ‚Üê USING THIS, Inverse AUC: 0.4268
Epoch 9, Train Loss: 0.9238, Val Loss: 0.9330, AUC: 0.5732
AUC: 0.5802 ‚Üê USING THIS, Inverse AUC: 0.4198
Epoch 10, Train Loss: 0.9229, Val Loss: 0.9330, AUC: 0.5802
AUC: 0.5834 ‚Üê USING THIS, Inverse AUC: 0.4166
Epoch 11, Train Loss: 0.9230, Val Loss: 0.9327, AUC: 0.5834
AUC: 0.5944 ‚Üê USING THIS, Inverse AUC: 0.4056
Epoch 12, Train Loss: 0.9223, Val Loss: 0.9327, AUC: 0.5944
AUC: 0.6123 ‚Üê USING THIS, Inverse AUC: 0.3877
Epoch 13, Train Loss: 0.9201, Val Loss: 0.9324, AUC: 0.6123
AUC: 0.6162 ‚Üê USING THIS, Inverse AUC: 0.3838
Epoch 14, Train Loss: 0.9236, Val Loss: 0.9323, AUC: 0.6162
AUC: 0.6214 ‚Üê USING THIS, Inverse AUC: 0.3786
Epoch 15, Train Loss: 0.9210, Val Loss: 0.9321, AUC: 0.6214
AUC: 0.6233 ‚Üê USING THIS, Inverse AUC: 0.3767
Epoch 16, Train Loss: 0.9216, Val Loss: 0.9322, AUC: 0.6233
AUC: 0.6226 ‚Üê USING THIS, Inverse AUC: 0.3774
Epoch 17, Train Loss: 0.9223, Val Loss: 0.9314, AUC: 0.6226
AUC: 0.6215 ‚Üê USING THIS, Inverse AUC: 0.3785
Epoch 18, Train Loss: 0.9220, Val Loss: 0.9323, AUC: 0.6215
AUC: 0.6224 ‚Üê USING THIS, Inverse AUC: 0.3776
Epoch 19, Train Loss: 0.9183, Val Loss: 0.9325, AUC: 0.6224
AUC: 0.6190 ‚Üê USING THIS, Inverse AUC: 0.3810
Epoch 20, Train Loss: 0.9218, Val Loss: 0.9321, AUC: 0.6190
AUC: 0.6179 ‚Üê USING THIS, Inverse AUC: 0.3821
Epoch 21, Train Loss: 0.9213, Val Loss: 0.9319, AUC: 0.6179
AUC: 0.6227 ‚Üê USING THIS, Inverse AUC: 0.3773
Epoch 22, Train Loss: 0.9203, Val Loss: 0.9315, AUC: 0.6227
AUC: 0.6267 ‚Üê USING THIS, Inverse AUC: 0.3733
Epoch 23, Train Loss: 0.9209, Val Loss: 0.9307, AUC: 0.6267
AUC: 0.6290 ‚Üê USING THIS, Inverse AUC: 0.3710
Epoch 24, Train Loss: 0.9215, Val Loss: 0.9306, AUC: 0.6290
AUC: 0.6238 ‚Üê USING THIS, Inverse AUC: 0.3762
Epoch 25, Train Loss: 0.9200, Val Loss: 0.9316, AUC: 0.6238
AUC: 0.6246 ‚Üê USING THIS, Inverse AUC: 0.3754
Epoch 26, Train Loss: 0.9207, Val Loss: 0.9307, AUC: 0.6246
AUC: 0.6272 ‚Üê USING THIS, Inverse AUC: 0.3728
Epoch 27, Train Loss: 0.9216, Val Loss: 0.9302, AUC: 0.6272
AUC: 0.6261 ‚Üê USING THIS, Inverse AUC: 0.3739
Epoch 28, Train Loss: 0.9207, Val Loss: 0.9305, AUC: 0.6261
AUC: 0.6272 ‚Üê USING THIS, Inverse AUC: 0.3728
Epoch 29, Train Loss: 0.9198, Val Loss: 0.9301, AUC: 0.6272
AUC: 0.6246 ‚Üê USING THIS, Inverse AUC: 0.3754
Epoch 30, Train Loss: 0.9196, Val Loss: 0.9302, AUC: 0.6246
AUC: 0.6270 ‚Üê USING THIS, Inverse AUC: 0.3730
Epoch 31, Train Loss: 0.9199, Val Loss: 0.9293, AUC: 0.6270
AUC: 0.6233 ‚Üê USING THIS, Inverse AUC: 0.3767
Epoch 32, Train Loss: 0.9174, Val Loss: 0.9295, AUC: 0.6233
AUC: 0.6227 ‚Üê USING THIS, Inverse AUC: 0.3773
Epoch 33, Train Loss: 0.9180, Val Loss: 0.9296, AUC: 0.6227
AUC: 0.6220 ‚Üê USING THIS, Inverse AUC: 0.3780
Epoch 34, Train Loss: 0.9180, Val Loss: 0.9291, AUC: 0.6220
AUC: 0.6215 ‚Üê USING THIS, Inverse AUC: 0.3785
Epoch 35, Train Loss: 0.9183, Val Loss: 0.9290, AUC: 0.6215
AUC: 0.6228 ‚Üê USING THIS, Inverse AUC: 0.3772
Epoch 36, Train Loss: 0.9188, Val Loss: 0.9280, AUC: 0.6228
AUC: 0.6236 ‚Üê USING THIS, Inverse AUC: 0.3764
Epoch 37, Train Loss: 0.9175, Val Loss: 0.9275, AUC: 0.6236
AUC: 0.6268 ‚Üê USING THIS, Inverse AUC: 0.3732
Epoch 38, Train Loss: 0.9185, Val Loss: 0.9272, AUC: 0.6268
AUC: 0.6293 ‚Üê USING THIS, Inverse AUC: 0.3707
Epoch 39, Train Loss: 0.9169, Val Loss: 0.9266, AUC: 0.6293
AUC: 0.6298 ‚Üê USING THIS, Inverse AUC: 0.3702
Epoch 40, Train Loss: 0.9159, Val Loss: 0.9276, AUC: 0.6298
AUC: 0.6335 ‚Üê USING THIS, Inverse AUC: 0.3665
Epoch 41, Train Loss: 0.9166, Val Loss: 0.9264, AUC: 0.6335
AUC: 0.6321 ‚Üê USING THIS, Inverse AUC: 0.3679
Epoch 42, Train Loss: 0.9139, Val Loss: 0.9265, AUC: 0.6321
AUC: 0.6322 ‚Üê USING THIS, Inverse AUC: 0.3678
Epoch 43, Train Loss: 0.9162, Val Loss: 0.9263, AUC: 0.6322
AUC: 0.6328 ‚Üê USING THIS, Inverse AUC: 0.3672
Epoch 44, Train Loss: 0.9125, Val Loss: 0.9254, AUC: 0.6328
AUC: 0.6322 ‚Üê USING THIS, Inverse AUC: 0.3678
Epoch 45, Train Loss: 0.9170, Val Loss: 0.9246, AUC: 0.6322
AUC: 0.6322 ‚Üê USING THIS, Inverse AUC: 0.3678
Epoch 46, Train Loss: 0.9095, Val Loss: 0.9243, AUC: 0.6322
AUC: 0.6305 ‚Üê USING THIS, Inverse AUC: 0.3695
Epoch 47, Train Loss: 0.9133, Val Loss: 0.9258, AUC: 0.6305
AUC: 0.6339 ‚Üê USING THIS, Inverse AUC: 0.3661
Epoch 48, Train Loss: 0.9135, Val Loss: 0.9236, AUC: 0.6339
AUC: 0.6335 ‚Üê USING THIS, Inverse AUC: 0.3665
Epoch 49, Train Loss: 0.9114, Val Loss: 0.9235, AUC: 0.6335
AUC: 0.6359 ‚Üê USING THIS, Inverse AUC: 0.3641
Epoch 50, Train Loss: 0.9101, Val Loss: 0.9223, AUC: 0.6359
AUC: 0.6376 ‚Üê USING THIS, Inverse AUC: 0.3624
Epoch 51, Train Loss: 0.9094, Val Loss: 0.9217, AUC: 0.6376
AUC: 0.6379 ‚Üê USING THIS, Inverse AUC: 0.3621
Epoch 52, Train Loss: 0.9095, Val Loss: 0.9217, AUC: 0.6379
AUC: 0.6378 ‚Üê USING THIS, Inverse AUC: 0.3622
Epoch 53, Train Loss: 0.9090, Val Loss: 0.9203, AUC: 0.6378
AUC: 0.6364 ‚Üê USING THIS, Inverse AUC: 0.3636
Epoch 54, Train Loss: 0.9086, Val Loss: 0.9205, AUC: 0.6364
AUC: 0.6371 ‚Üê USING THIS, Inverse AUC: 0.3629
Epoch 55, Train Loss: 0.9073, Val Loss: 0.9192, AUC: 0.6371
AUC: 0.6356 ‚Üê USING THIS, Inverse AUC: 0.3644
Epoch 56, Train Loss: 0.9088, Val Loss: 0.9193, AUC: 0.6356
AUC: 0.6366 ‚Üê USING THIS, Inverse AUC: 0.3634
Epoch 57, Train Loss: 0.9056, Val Loss: 0.9189, AUC: 0.6366
AUC: 0.6351 ‚Üê USING THIS, Inverse AUC: 0.3649
Epoch 58, Train Loss: 0.9077, Val Loss: 0.9190, AUC: 0.6351
AUC: 0.6335 ‚Üê USING THIS, Inverse AUC: 0.3665
Epoch 59, Train Loss: 0.9064, Val Loss: 0.9183, AUC: 0.6335
AUC: 0.6337 ‚Üê USING THIS, Inverse AUC: 0.3663
Epoch 60, Train Loss: 0.9035, Val Loss: 0.9179, AUC: 0.6337
AUC: 0.6338 ‚Üê USING THIS, Inverse AUC: 0.3662
Epoch 61, Train Loss: 0.9050, Val Loss: 0.9183, AUC: 0.6338
AUC: 0.6343 ‚Üê USING THIS, Inverse AUC: 0.3657
Epoch 62, Train Loss: 0.9025, Val Loss: 0.9167, AUC: 0.6343
AUC: 0.6339 ‚Üê USING THIS, Inverse AUC: 0.3661
Epoch 63, Train Loss: 0.9035, Val Loss: 0.9179, AUC: 0.6339
AUC: 0.6323 ‚Üê USING THIS, Inverse AUC: 0.3677
Epoch 64, Train Loss: 0.9006, Val Loss: 0.9163, AUC: 0.6323
AUC: 0.6321 ‚Üê USING THIS, Inverse AUC: 0.3679
Epoch 65, Train Loss: 0.8980, Val Loss: 0.9165, AUC: 0.6321
AUC: 0.6329 ‚Üê USING THIS, Inverse AUC: 0.3671
Epoch 66, Train Loss: 0.8983, Val Loss: 0.9158, AUC: 0.6329
AUC: 0.6341 ‚Üê USING THIS, Inverse AUC: 0.3659
Epoch 67, Train Loss: 0.8976, Val Loss: 0.9155, AUC: 0.6341
AUC: 0.6343 ‚Üê USING THIS, Inverse AUC: 0.3657
Epoch 68, Train Loss: 0.8977, Val Loss: 0.9146, AUC: 0.6343
AUC: 0.6325 ‚Üê USING THIS, Inverse AUC: 0.3675
Epoch 69, Train Loss: 0.8965, Val Loss: 0.9147, AUC: 0.6325
AUC: 0.6324 ‚Üê USING THIS, Inverse AUC: 0.3676
Epoch 70, Train Loss: 0.8916, Val Loss: 0.9145, AUC: 0.6324
AUC: 0.6307 ‚Üê USING THIS, Inverse AUC: 0.3693
Epoch 71, Train Loss: 0.8987, Val Loss: 0.9151, AUC: 0.6307
AUC: 0.6304 ‚Üê USING THIS, Inverse AUC: 0.3696
Epoch 72, Train Loss: 0.8915, Val Loss: 0.9147, AUC: 0.6304
AUC: 0.6323 ‚Üê USING THIS, Inverse AUC: 0.3677
Epoch 73, Train Loss: 0.8956, Val Loss: 0.9127, AUC: 0.6323
AUC: 0.6352 ‚Üê USING THIS, Inverse AUC: 0.3648
Epoch 74, Train Loss: 0.8963, Val Loss: 0.9120, AUC: 0.6352
AUC: 0.6354 ‚Üê USING THIS, Inverse AUC: 0.3646
Epoch 75, Train Loss: 0.8953, Val Loss: 0.9112, AUC: 0.6354
AUC: 0.6334 ‚Üê USING THIS, Inverse AUC: 0.3666
Epoch 76, Train Loss: 0.8955, Val Loss: 0.9115, AUC: 0.6334
AUC: 0.6351 ‚Üê USING THIS, Inverse AUC: 0.3649
Epoch 77, Train Loss: 0.8921, Val Loss: 0.9112, AUC: 0.6351
AUC: 0.6347 ‚Üê USING THIS, Inverse AUC: 0.3653
Epoch 78, Train Loss: 0.8962, Val Loss: 0.9105, AUC: 0.6347
AUC: 0.6381 ‚Üê USING THIS, Inverse AUC: 0.3619
Epoch 79, Train Loss: 0.8885, Val Loss: 0.9099, AUC: 0.6381
AUC: 0.6347 ‚Üê USING THIS, Inverse AUC: 0.3653
Epoch 80, Train Loss: 0.8908, Val Loss: 0.9135, AUC: 0.6347
AUC: 0.6344 ‚Üê USING THIS, Inverse AUC: 0.3656
Epoch 81, Train Loss: 0.8821, Val Loss: 0.9105, AUC: 0.6344
AUC: 0.6327 ‚Üê USING THIS, Inverse AUC: 0.3673
Epoch 82, Train Loss: 0.8839, Val Loss: 0.9109, AUC: 0.6327
AUC: 0.6319 ‚Üê USING THIS, Inverse AUC: 0.3681
Epoch 83, Train Loss: 0.8856, Val Loss: 0.9114, AUC: 0.6319
AUC: 0.6331 ‚Üê USING THIS, Inverse AUC: 0.3669
Epoch 84, Train Loss: 0.8853, Val Loss: 0.9100, AUC: 0.6331
AUC: 0.6339 ‚Üê USING THIS, Inverse AUC: 0.3661
Epoch 85, Train Loss: 0.8915, Val Loss: 0.9103, AUC: 0.6339
AUC: 0.6363 ‚Üê USING THIS, Inverse AUC: 0.3637
Epoch 86, Train Loss: 0.8810, Val Loss: 0.9119, AUC: 0.6363
AUC: 0.6356 ‚Üê USING THIS, Inverse AUC: 0.3644
Epoch 87, Train Loss: 0.8797, Val Loss: 0.9084, AUC: 0.6356
AUC: 0.6392 ‚Üê USING THIS, Inverse AUC: 0.3608
Epoch 88, Train Loss: 0.8837, Val Loss: 0.9079, AUC: 0.6392
AUC: 0.6402 ‚Üê USING THIS, Inverse AUC: 0.3598
Epoch 89, Train Loss: 0.8825, Val Loss: 0.9066, AUC: 0.6402
AUC: 0.6414 ‚Üê USING THIS, Inverse AUC: 0.3586
Epoch 90, Train Loss: 0.8812, Val Loss: 0.9103, AUC: 0.6414
AUC: 0.6408 ‚Üê USING THIS, Inverse AUC: 0.3592
Epoch 91, Train Loss: 0.8782, Val Loss: 0.9055, AUC: 0.6408
AUC: 0.6397 ‚Üê USING THIS, Inverse AUC: 0.3603
Epoch 92, Train Loss: 0.8734, Val Loss: 0.9059, AUC: 0.6397
AUC: 0.6391 ‚Üê USING THIS, Inverse AUC: 0.3609
Epoch 93, Train Loss: 0.8834, Val Loss: 0.9058, AUC: 0.6391
AUC: 0.6398 ‚Üê USING THIS, Inverse AUC: 0.3602
Epoch 94, Train Loss: 0.8853, Val Loss: 0.9057, AUC: 0.6398
AUC: 0.6385 ‚Üê USING THIS, Inverse AUC: 0.3615
Epoch 95, Train Loss: 0.8790, Val Loss: 0.9051, AUC: 0.6385
AUC: 0.6412 ‚Üê USING THIS, Inverse AUC: 0.3588
Epoch 96, Train Loss: 0.8799, Val Loss: 0.9057, AUC: 0.6412
AUC: 0.6411 ‚Üê USING THIS, Inverse AUC: 0.3589
Epoch 97, Train Loss: 0.8730, Val Loss: 0.9042, AUC: 0.6411
AUC: 0.6401 ‚Üê USING THIS, Inverse AUC: 0.3599
Epoch 98, Train Loss: 0.8726, Val Loss: 0.9048, AUC: 0.6401
AUC: 0.6395 ‚Üê USING THIS, Inverse AUC: 0.3605
Epoch 99, Train Loss: 0.8827, Val Loss: 0.9049, AUC: 0.6395
AUC: 0.6399 ‚Üê USING THIS, Inverse AUC: 0.3601
Epoch 100, Train Loss: 0.8736, Val Loss: 0.9060, AUC: 0.6399
üìà Saved loss plot to TNBC_results/fold_1_seed_2025_20250414-101127/loss_plot.png
üîç Evaluating...
üîç Predicted probabilities: mean=0.4803, min=0.3439, max=0.6319
Standard AUC: 0.6411
Inverse AUC: 0.3589
Using standard predictions (AUC: 0.6411)

üìä Threshold sweep:
 Thresh |    Acc |   Prec |    Rec |   Spec |     F1
--------------------------------------------------
   0.30 |  0.348 |  0.348 |  1.000 |  0.348 |  0.516
   0.31 |  0.348 |  0.348 |  1.000 |  0.348 |  0.516
   0.32 |  0.348 |  0.348 |  1.000 |  0.348 |  0.516
   0.33 |  0.348 |  0.348 |  1.000 |  0.348 |  0.516
   0.34 |  0.348 |  0.348 |  1.000 |  0.348 |  0.516
   0.35 |  0.348 |  0.347 |  0.990 |  0.348 |  0.514
   0.36 |  0.348 |  0.345 |  0.971 |  0.348 |  0.509
   0.37 |  0.351 |  0.345 |  0.961 |  0.351 |  0.508
   0.38 |  0.382 |  0.355 |  0.951 |  0.382 |  0.517
   0.39 |  0.395 |  0.354 |  0.893 |  0.395 |  0.507
   0.40 |  0.416 |  0.360 |  0.874 |  0.416 |  0.510
   0.41 |  0.463 |  0.378 |  0.845 |  0.463 |  0.523
   0.42 |  0.473 |  0.379 |  0.806 |  0.473 |  0.516
   0.43 |  0.493 |  0.388 |  0.786 |  0.493 |  0.519
   0.44 |  0.524 |  0.404 |  0.777 |  0.524 |  0.532
   0.45 |  0.557 |  0.423 |  0.748 |  0.557 |  0.540
   0.46 |  0.564 |  0.424 |  0.709 |  0.564 |  0.531
   0.47 |  0.591 |  0.442 |  0.670 |  0.591 |  0.533
   0.48 |  0.598 |  0.446 |  0.641 |  0.598 |  0.526
   0.49 |  0.611 |  0.455 |  0.583 |  0.611 |  0.511
   0.50 |  0.639 |  0.482 |  0.534 |  0.639 |  0.507
   0.51 |  0.655 |  0.505 |  0.505 |  0.655 |  0.505
   0.52 |  0.652 |  0.500 |  0.437 |  0.652 |  0.466
   0.53 |  0.669 |  0.530 |  0.427 |  0.669 |  0.473
   0.54 |  0.662 |  0.521 |  0.369 |  0.662 |  0.432
   0.55 |  0.682 |  0.571 |  0.350 |  0.682 |  0.434
   0.56 |  0.662 |  0.531 |  0.252 |  0.662 |  0.342
   0.57 |  0.669 |  0.558 |  0.233 |  0.669 |  0.329
   0.58 |  0.686 |  0.656 |  0.204 |  0.686 |  0.311
   0.59 |  0.672 |  0.650 |  0.126 |  0.672 |  0.211
   0.60 |  0.672 |  0.688 |  0.107 |  0.672 |  0.185
   0.61 |  0.666 |  0.700 |  0.068 |  0.666 |  0.124
   0.62 |  0.662 |  0.800 |  0.039 |  0.662 |  0.074
   0.63 |  0.655 |  1.000 |  0.010 |  0.655 |  0.019
   0.64 |  0.652 |  0.000 |  0.000 |  0.652 |  0.000
   0.65 |  0.652 |  0.000 |  0.000 |  0.652 |  0.000
   0.66 |  0.652 |  0.000 |  0.000 |  0.652 |  0.000
   0.67 |  0.652 |  0.000 |  0.000 |  0.652 |  0.000
   0.68 |  0.652 |  0.000 |  0.000 |  0.652 |  0.000
   0.69 |  0.652 |  0.000 |  0.000 |  0.652 |  0.000

üéØ Best Threshold: 0.45 (F1=0.540)
Accuracy:  0.5574
Precision: 0.4231
Recall:    0.7476
F1 Score:  0.5404
Confusion Matrix:
[[ 88 105]
 [ 26  77]]
üîç Visualizing features...
‚úÖ Initialized TNBCDataset with 1184 patients | mode=delta2 | segmentation=True
‚úÖ Initialized TNBCDataset with 296 patients | mode=delta2 | segmentation=True
Using TNBCNet model
üîÑ Fold 2
‚úÖ Applied custom weight initialization
Class distribution: 402 positives, 782 negatives
Using pos_weight: 1.95
üîç Finding optimal learning rate...
üöÄ Training...
AUC: 0.5132 ‚Üê USING THIS, Inverse AUC: 0.4868
Epoch 1, Train Loss: 0.9171, Val Loss: 0.8963, AUC: 0.5132
AUC: 0.5057 ‚Üê USING THIS, Inverse AUC: 0.4943
Epoch 2, Train Loss: 0.9174, Val Loss: 0.8964, AUC: 0.5057
AUC: 0.5000, Inverse AUC: 0.5000 ‚Üê USING THIS
Epoch 3, Train Loss: 0.9185, Val Loss: 0.8971, AUC: 0.5000
AUC: 0.5120 ‚Üê USING THIS, Inverse AUC: 0.4880
Epoch 4, Train Loss: 0.9157, Val Loss: 0.8978, AUC: 0.5120
AUC: 0.5112 ‚Üê USING THIS, Inverse AUC: 0.4888
Epoch 5, Train Loss: 0.9166, Val Loss: 0.8974, AUC: 0.5112
AUC: 0.5101 ‚Üê USING THIS, Inverse AUC: 0.4899
Epoch 6, Train Loss: 0.9138, Val Loss: 0.8971, AUC: 0.5101
AUC: 0.5149 ‚Üê USING THIS, Inverse AUC: 0.4851
Epoch 7, Train Loss: 0.9138, Val Loss: 0.8963, AUC: 0.5149
AUC: 0.5046 ‚Üê USING THIS, Inverse AUC: 0.4954
Epoch 8, Train Loss: 0.9177, Val Loss: 0.8970, AUC: 0.5046
AUC: 0.4979, Inverse AUC: 0.5021 ‚Üê USING THIS
Epoch 9, Train Loss: 0.9138, Val Loss: 0.8965, AUC: 0.5021
AUC: 0.5051 ‚Üê USING THIS, Inverse AUC: 0.4949
Epoch 10, Train Loss: 0.9165, Val Loss: 0.8966, AUC: 0.5051
AUC: 0.5121 ‚Üê USING THIS, Inverse AUC: 0.4879
Epoch 11, Train Loss: 0.9164, Val Loss: 0.8966, AUC: 0.5121
‚èπÔ∏è Early stopping at epoch 11
üìà Saved loss plot to TNBC_results/fold_2_seed_2025_20250414-101127/loss_plot.png
üîç Evaluating...
üîç Predicted probabilities: mean=0.4909, min=0.4819, max=0.5015
Standard AUC: 0.5149
Inverse AUC: 0.4851
Using standard predictions (AUC: 0.5149)

üìä Threshold sweep:
 Thresh |    Acc |   Prec |    Rec |   Spec |     F1
--------------------------------------------------
   0.30 |  0.328 |  0.328 |  1.000 |  0.328 |  0.494
   0.31 |  0.328 |  0.328 |  1.000 |  0.328 |  0.494
   0.32 |  0.328 |  0.328 |  1.000 |  0.328 |  0.494
   0.33 |  0.328 |  0.328 |  1.000 |  0.328 |  0.494
   0.34 |  0.328 |  0.328 |  1.000 |  0.328 |  0.494
   0.35 |  0.328 |  0.328 |  1.000 |  0.328 |  0.494
   0.36 |  0.328 |  0.328 |  1.000 |  0.328 |  0.494
   0.37 |  0.328 |  0.328 |  1.000 |  0.328 |  0.494
   0.38 |  0.328 |  0.328 |  1.000 |  0.328 |  0.494
   0.39 |  0.328 |  0.328 |  1.000 |  0.328 |  0.494
   0.40 |  0.328 |  0.328 |  1.000 |  0.328 |  0.494
   0.41 |  0.328 |  0.328 |  1.000 |  0.328 |  0.494
   0.42 |  0.328 |  0.328 |  1.000 |  0.328 |  0.494
   0.43 |  0.328 |  0.328 |  1.000 |  0.328 |  0.494
   0.44 |  0.328 |  0.328 |  1.000 |  0.328 |  0.494
   0.45 |  0.328 |  0.328 |  1.000 |  0.328 |  0.494
   0.46 |  0.328 |  0.328 |  1.000 |  0.328 |  0.494
   0.47 |  0.328 |  0.328 |  1.000 |  0.328 |  0.494
   0.48 |  0.328 |  0.328 |  1.000 |  0.328 |  0.494
   0.49 |  0.473 |  0.327 |  0.577 |  0.473 |  0.418
   0.50 |  0.679 |  1.000 |  0.021 |  0.679 |  0.040
   0.51 |  0.672 |  0.000 |  0.000 |  0.672 |  0.000
   0.52 |  0.672 |  0.000 |  0.000 |  0.672 |  0.000
   0.53 |  0.672 |  0.000 |  0.000 |  0.672 |  0.000
   0.54 |  0.672 |  0.000 |  0.000 |  0.672 |  0.000
   0.55 |  0.672 |  0.000 |  0.000 |  0.672 |  0.000
   0.56 |  0.672 |  0.000 |  0.000 |  0.672 |  0.000
   0.57 |  0.672 |  0.000 |  0.000 |  0.672 |  0.000
   0.58 |  0.672 |  0.000 |  0.000 |  0.672 |  0.000
   0.59 |  0.672 |  0.000 |  0.000 |  0.672 |  0.000
   0.60 |  0.672 |  0.000 |  0.000 |  0.672 |  0.000
   0.61 |  0.672 |  0.000 |  0.000 |  0.672 |  0.000
   0.62 |  0.672 |  0.000 |  0.000 |  0.672 |  0.000
   0.63 |  0.672 |  0.000 |  0.000 |  0.672 |  0.000
   0.64 |  0.672 |  0.000 |  0.000 |  0.672 |  0.000
   0.65 |  0.672 |  0.000 |  0.000 |  0.672 |  0.000
   0.66 |  0.672 |  0.000 |  0.000 |  0.672 |  0.000
   0.67 |  0.672 |  0.000 |  0.000 |  0.672 |  0.000
   0.68 |  0.672 |  0.000 |  0.000 |  0.672 |  0.000
   0.69 |  0.672 |  0.000 |  0.000 |  0.672 |  0.000

üéØ Best Threshold: 0.30 (F1=0.494)
Accuracy:  0.3277
Precision: 0.3277
Recall:    1.0000
F1 Score:  0.4936
Confusion Matrix:
[[  0 199]
 [  0  97]]
üîç Visualizing features...
‚úÖ Initialized TNBCDataset with 1184 patients | mode=delta2 | segmentation=True
‚úÖ Initialized TNBCDataset with 296 patients | mode=delta2 | segmentation=True
Using TNBCNet model
üîÑ Fold 3
‚úÖ Applied custom weight initialization
Class distribution: 390 positives, 794 negatives
Using pos_weight: 2.04
üîç Finding optimal learning rate...
üöÄ Training...
AUC: 0.4804, Inverse AUC: 0.5196 ‚Üê USING THIS
Epoch 1, Train Loss: 0.9293, Val Loss: 0.9505, AUC: 0.5196
AUC: 0.4910, Inverse AUC: 0.5090 ‚Üê USING THIS
Epoch 2, Train Loss: 0.9297, Val Loss: 0.9510, AUC: 0.5090
AUC: 0.5058 ‚Üê USING THIS, Inverse AUC: 0.4942
Epoch 3, Train Loss: 0.9300, Val Loss: 0.9512, AUC: 0.5058
AUC: 0.5134 ‚Üê USING THIS, Inverse AUC: 0.4866
Epoch 4, Train Loss: 0.9304, Val Loss: 0.9512, AUC: 0.5134
AUC: 0.5232 ‚Üê USING THIS, Inverse AUC: 0.4768
Epoch 5, Train Loss: 0.9287, Val Loss: 0.9508, AUC: 0.5232
AUC: 0.5251 ‚Üê USING THIS, Inverse AUC: 0.4749
Epoch 6, Train Loss: 0.9300, Val Loss: 0.9507, AUC: 0.5251
AUC: 0.5326 ‚Üê USING THIS, Inverse AUC: 0.4674
Epoch 7, Train Loss: 0.9278, Val Loss: 0.9502, AUC: 0.5326
AUC: 0.5197 ‚Üê USING THIS, Inverse AUC: 0.4803
Epoch 8, Train Loss: 0.9288, Val Loss: 0.9511, AUC: 0.5197
AUC: 0.5252 ‚Üê USING THIS, Inverse AUC: 0.4748
Epoch 9, Train Loss: 0.9289, Val Loss: 0.9511, AUC: 0.5252
AUC: 0.5334 ‚Üê USING THIS, Inverse AUC: 0.4666
Epoch 10, Train Loss: 0.9291, Val Loss: 0.9518, AUC: 0.5334
